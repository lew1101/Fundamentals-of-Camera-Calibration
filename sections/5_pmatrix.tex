\section{Projection Matrix} \label{sec:projection}

When we combine the equation for the intrinsic transformation, $\vec{p}_i = K\vec{p}_c$ (eq. \ref{eq:pi}), with the equation for the extrinsic transformation, $\vec{p_c} = T\vec{p}_w$ (eq. \ref{eq:pc}), we obtain:
\begin{equation} \label{eq:combined}
    \vec{p}_{i} = KT\vec{p}_{w}
\end{equation}

This single equation encapsulates the relationship between the world coordinates and its corresponding pixel coordinates. However, since that our goal is to solve for $K$ and $T$ for a particular camera when given the mappings of 3D coordinates to their pixel coordinates, it is much easier to solve for the matrix product $KT$ as opposed to each of the matrices individually. As such, we simplify our camera model by defining a new matrix, $P$, which is equal to the product $KT$. Since $K$ is a $3 \times 3$ matrix and $T$ is a $3 \times 4$ matrix, $KT$ yields a $3 \times 4$ matrix. 
\begin{equation}
    \underbrace{
        \begin{bmatrix}
        p_{11} & p_{12} & p_{13} & p_{14} \\
        p_{21} & p_{22} & p_{23} & p_{24} \\
        p_{31} & p_{32} & p_{33} & p_{34}
    \end{bmatrix}
    }_{\mathlarger{P}}
    \equiv
    \underbrace{
        \begin{bmatrix}
            f_x & 0   & c_x \\
            0   & f_y & c_y \\
            0   & 0   & 1
        \end{bmatrix}
    }_{\mathlarger{K}}
    \underbrace{
        \begin{bmatrix}
            r_{11} & r_{12} & r_{13} & t_x \\
            r_{21} & r_{22} & r_{23} & t_y \\
            r_{31} & r_{32} & r_{33} & t_z \\
        \end{bmatrix}
    }_{\mathlarger{T}}
\end{equation}

Replacing $P$ for $K\,T$ in equation \ref{eq:combined}, we obtain:
\begin{equation} \label{eq:project}
    \vec{p}_{i} = P\,\vec{p}_{w}
\end{equation}

When expressing the pixel coordinate in homogenous coordinates, equation \ref{eq:project} becomes
\begin{equation} \label{eq:proj}
    \begin{bmatrix}
        \widetilde{u}_n \\ \widetilde{v}_n \\ \widetilde{w}_n
    \end{bmatrix}
    =
    \begin{bmatrix}
        p_{11} & p_{12} & p_{13} & p_{14} \\
        p_{21} & p_{22} & p_{23} & p_{24} \\
        p_{31} & p_{32} & p_{33} & p_{34}
    \end{bmatrix}
    \begin{bmatrix}
        x_w^{(n)} \\ y_w^{(n)} \\ z_w^{(n)} \\ 1
    \end{bmatrix}
\end{equation}

The implications of this equation is very important, as it means that a $3 \times 4$ matrix is sufficient in describing the relationship between a point in the world coordinate frame to its projection onto the image plane in pixel coordinates.

\subsection{Solving for the Projection Matrix}

Now, we need to devise a way to solve for the projection matrix. Rewriting the matrix equation \ref{eq:project} as a system of equations, we obtain:

\begin{align*}
    \widetilde{u}_n = p_{11}x_w^{(n)} + p_{12}y_w^{(n)} + p_{13}z_w^{(n)} + p_{14} \\
    \widetilde{v}_n = p_{21}x_w^{(n)} + p_{22}y_w^{(n)} + p_{23}z_w^{(n)} + p_{24} \\
    \widetilde{w}_n = p_{31}x_w^{(n)} + p_{32}y_w^{(n)} + p_{33}z_w^{(n)} + p_{34}
\end{align*}
We convert the pixel coordinates homogenous coordinates to their inhomogeneous coordinates by dividing $\widetilde{u}_n$ and $\widetilde{v}_n$ by $\widetilde{w}_n$. 
\begin{align*}
    u_n & = \frac{\widetilde{u}_n}{\widetilde{w}_n} = \frac{p_{11}x_w^{(n)} + p_{12}y_w^{(n)} + p_{13}z_w^{(n)} + p_{14}}{p_{31}x_w^{(n)} + p_{32}y_w^{(n)} + p_{33}z_w^{(n)} + p_{34}} \\
    v_n & = \frac{\widetilde{u}_n}{\widetilde{w}_n} = \frac{p_{21}x_w^{(n)} + p_{22}y_w^{(n)} + p_{23}z_w^{(n)} + p_{24}}{p_{31}x_w^{(n)} + p_{32}y_w^{(n)} + p_{33}z_w^{(n)} + p_{34}}
\end{align*}

\begin{align*}
    u_n(p_{31}x_w^{(n)} + p_{32}y_w^{(n)} + p_{33}z_w^{(n)} + p_{34}) = p_{11}x_w^{(n)} + p_{12}y_w^{(n)} + p_{13}z_w^{(n)} + p_{14} \\
    v_n(p_{31}x_w^{(n)} + p_{32}y_w^{(n)} + p_{33}z_w^{(n)} + p_{34}) = p_{21}x_w^{(n)} + p_{22}y_w^{(n)} + p_{23}z_w^{(n)} + p_{24}
\end{align*}

\begin{subequations}
    \begin{align}
        0 = p_{11}x_w^{(n)} + p_{12}y_w^{(n)} + p_{13}z_w^{(n)} + p_{14} - p_{31}u_nx_w^{(n)} - p_{32}u_ny_w^{(n)} - p_{33}u_nz_w^{(n)} - p_{34}u_n \\
        0 = p_{21}x_w^{(n)} + p_{22}y_w^{(n)} + p_{23}z_w^{(n)} + p_{24} - p_{31}v_nx_w^{(n)} - p_{32}v_ny_w^{(n)} - p_{33}v_nz_w^{(n)} - p_{34}v_n
    \end{align}
\end{subequations}

\setcounter{MaxMatrixCols}{20}
\begin{equation}
    \scalemath{0.9}{
    \begin{bmatrix}
        0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0
    \end{bmatrix}
    =
    \underbrace{
        \begin{blockarray}{[*{12}c]}
            x_w^{(1)} & y_w^{(1)} & z_w^{(1)} & 1 & 0         & 0         & 0         & 0 & -u_1 x_w^{(1)} & -u_1 y_w^{(1)} & -u_1 z_w^{(1)} & -u_1 \\
            0         & 0         & 0         & 0 & x_w^{(1)} & y_w^{(1)} & z_w^{(1)} & 1 & -v_1 x_w^{(1)} & -v_1 y_w^{(1)} & -v_1 z_w^{(1)} & -v_1 \\
            \BAmulticolumn{6}{c}{\vdots} & \BAmulticolumn{6}{c}{\vdots} \\
            x_w^{(n)} & y_w^{(n)} & z_w^{(n)} & 1 & 0         & 0         & 0         & 0 & -u_n x_w^{(n)} & -u_n y_w^{(n)} & -u_n z_w^{(n)} & -u_n \\
            0         & 0         & 0         & 0 & x_w^{(n)} & y_w^{(n)} & z_w^{(n)} & 1 & -v_n x_w^{(n)} & -v_n y_w^{(n)} & -v_n z_w^{(n)} & -v_n
        \end{blockarray}
    }_{\mathlarger{G}}
    \underbrace{
        \begin{bmatrix}
            p_{11} \\ p_{12} \\ p_{13} \\ p_{14} \\ p_{21} \\ p_{22} \\ p_{23} \\ p_{24} \\ p_{31} \\ p_{32} \\ p_{33} \\ p_{34}
        \end{bmatrix}
    }_{\mathlarger{p}}
    }
\end{equation}

homogenous linear system
overdetermined 


\subsection{Constrained Least Squares Solution}

We have now established a way to solve for the

Now, we need to solve for $Gp = 0$
\begin{equation} \label{eq:min1}
    \optmin{p}{\lVert Gp \rVert^2}{\lVert p \rVert^2 = 1}
\end{equation}
For a given arbitrary vector $v \in \mathbb{R}^n$, the magnitude is equal to $\sqrt{v_1^2+v_2^2+ \cdots + v_n^2}$. As such, we can rewrite the square of the magnitude of $v$, $\Vert v \Vert ^2$, as:
\begin{equation*}
    \Vert v \Vert^2
    = v_1^2+v_2^2+ \cdots v_n^2
    =
    \begin{bmatrix}
        v_1 & v_2 & \cdots & v_n
    \end{bmatrix}
    \begin{bmatrix}
        v_1 \\ v_2 \\ \vdots \\ v_n
    \end{bmatrix}
    = v^\T v
\end{equation*}
Thus, in equation \ref{eq:min1}, we can replace $\Vert Gp \Vert^2$ with $p^\T A^\T Gp$ and $\Vert p \Vert ^2$ for $p^\T p$ to obtain
\begin{equation} \label{eq:min2}
    \optmin{p}{\left(p^\T G^\T Gp\right)}{p^\T p = 1}
\end{equation}
The Lagrangian \footcite[][2]{ghojoghEigenvalueGeneralized2023} of equation \ref{eq:min2} is
\begin{equation}
    \mathcal{L}(p, \lambda) = p^\T G^\T Gp - \lambda \left( p^\T p - 1 \right)
\end{equation}
where $\lambda \in \mathbb{R}$ is the Lagrange multiplier. Since $p$ is minimized when $\mathcal{L}$ is minimized, we need to look for the absolute minimum of $\mathcal{L}$, which are located at its critical points. To find these points, we want to look for values of $p$ and $\lambda$ where all partial derivatives of the Lagrangian are zero, i.e.
\begin{equation*}
    \frac{\partial \mathcal{L}}{\partial p} = 0 \qquad \text{and} \qquad \frac{\partial \mathcal{L}}{\partial \lambda} = 0
\end{equation*}
where $\partial$ is used to denote a partial derivative (see Appendix \ref{sec:partial}). We will focus on the partial derivative of $\mathcal{L}$ with respect to $p$. Using product rule for partial derivatives, we obtain:
\begin{gather}
    \frac{\partial \mathcal{L}}{\partial p} = \frac{\partial}{\partial p} \left[ p^\T G^\T Gp - \lambda \left( p^\T p - 1 \right) \right] \seteq 0 \nonumber \\
    \Rightarrow 2G^\T Gp - 2 \lambda p = 0 \nonumber \\
    \Rightarrow G^\T Gp = \lambda p \label{eq:eigen}
\end{gather}
which is an eigenvalue problem for $G^\T G$. Potential solutions for $p$ are eigenvectors that satisfy equation \ref{eq:eigen}, \footcite[][]{nayarLinearCamera2021} with $\lambda \in \mathbb{R}$ as the eigenvalue. Since \ref{eq:min2} is a minimization problem, the minimized eigenvector $p$ is the one which has the smallest eigenvalue $\lambda$. \footcite[][2]{ghojoghEigenvalueGeneralized2023}

which states that for a given matrix $M \in \mathbb{R}^{n \times n}$, determine the eigenvector $x \in \mathbb{R}^n, x \neq 0$ and the eigenvalue $\lambda \in \mathbb{C}$ such that:



